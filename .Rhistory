summary(x=3)
summary(mean(x=3))
mewdata<-data.frame(wt=3)
predict(fit,newdata,interval=("preidct"))
predict(fit,newdata,interval=("predict"))
predict(fit,mewdata,interval=("predict"))
data(mtcars)
fit <- lm(mpg~wt,data=mtcars)
newdata<-data.frame(wt=3.00)
predict(fit,newdata,interval=("predict"))
newdata<-data.frame(wt=2.00)
predict(fit,newdata,interval=("predict"))
sumCoef <- summary(fit)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,30)*sumCoef[2,2]
0.5*sumCoef[2,1]+c(-1,1)*qt(.975,30)*sumCoef[2,2]
2*sumCoef[2,1]+c(-1,1)*qt(.975,30)*sumCoef[2,2]
2*(sumCoef[2,1]+c(-1,1)*qt(.975,30)*sumCoef[2,2])
fit <- lm(y~x)
fit
summary(fit)
summary(fit)$sigma
data(mtcars)
x<-mtcars$wt+3
y<-mtcars$mpg
fit <- lm(y~x)
fit
37.285-3*(-5.344)
lm(y)
x<-mtcars$wt
fit < lm(y~x)
fit <- lm(y~x)
fit1 <- lm(y~x-1)
fit
summary(fit)$sigma
summary(fit1)$sigma
summary(fit)$sigma/summary(fit1)$sigma
fit <- lm(y-1~x)
summary(fit)$sigma/summary(fit1)$sigma
fit
mean(y)
(y-mean(y))^2
sum((y-mean(y))^2)
sum((y-37.285-5.344*x)^2)
sum((y-37.285+5.344*x)^2)
1126.047/278.322
278.322/1126.047
library("AppliedPredictiveModeling", lib.loc="D:/R/R-3.1.0/library")
data(concrete)
library(caret)
set.seed(975)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training <- mixtures[ inTrain,]
testing <- mixtures[-inTrain,]
cutcrete<-cut2(training$CompressiveStrength, g=3)
library("Hmisc", lib.loc="D:/R/R-3.1.0/library")
cutcrete<-cut2(training$CompressiveStrength, g=4)
head(cutcrete)
head(testing)
plot(rownames(testing),cutcrete)
plot(rownames(training),cutcrete)
?plot
training$CompressiveStrength<-cut2(training$CompressiveStrength, g=4)
head(testing)
head(training)
library("ggplot2")
data(Wage)
library(ISLR)
install.packages("ISLR")
library(ISLR)
library(caret)
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
head(training)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
library(caret)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
install.packages("ggplot2")
install.packages("ggplot2")
library("ggplot2")
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
library(caret)
library(ISLR)
library(ggplot2)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
cutWage <- cut2(training$wage,g=3)
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
training$CompressiveStrength<-cut2(training$CompressiveStrength, g=4)
index <- rownames(training)
qplot(index, training$CompressiveStrength, color=training$Water)
qplot(index, training$CompressiveStrength, color=training$Water,fill=index,geom=c("boxplot"))
qplot(index, training$CompressiveStrength, color=training$Water,geom=c("boxplot"))
qplot(index, training$CompressiveStrength, color=training$Age)
qplot(training$CompressiveStrength, index, color=training$Water,geom=c("boxplot"))
head(index)
index <- c(1:744)
head(index)
qplot(training$CompressiveStrength, index, color=training$Water,geom=c("boxplot"))
index <- c(1:774)
qplot(training$CompressiveStrength, index, color=training$Water,geom=c("boxplot"))
length(index)
head(training)
head(index)
tail(index)
qplot(x=training$CompressiveStrength, y=index, color=training$Water,geom=c("boxplot"))
qplot(y=training$CompressiveStrength, x=index, color=training$Water,geom=c("boxplot"))
training$Cement <- index
head(training)
qplot(y=CopressiveStrength, x=Cement, data=training, color=Water)
qplot(y=CompressiveStrength, x=Cement, data=training, color=Water)
qplot(y=CompressiveStrength, x=Cement, data=training, color=CompressiveStrength)
qplot(y=CompressiveStrength, x=Cement, data=training, color=FlyAsh)
qplot(y=CompressiveStrength, x=Cement, data=training, color=Age)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cutC<- cut2(training$ComparessiveStrength,g=3)
cutC<- cut2(training$ComparessiveStrength,g=4)
cutC<- cut2(training$CompressiveStrength,g=4)
qplot(y=CompressiveStrength, x=nrow(training), data=training, color=cutC)
head(nrow(training)）
head(nrow(training))
qplot(y=training$CompressiveStrength, x=nrow(training), color=training$cutC)
index(training)
qplot(y=training$CompressiveStrength, x=c(1:nrow(training)), color=training$cutC)
qplot(y=training$CompressiveStrength, x=c(1:nrow(training)), col=training$cutC)
View(training)
View(training)
qplot(y=training$CompressiveStrength, x=c(1:nrow(training)), col=training$Age)
qplot(y=training$CompressiveStrength, x=c(1:nrow(training)), col=training$FlyAsh)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
head(Superplasticizer)
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
hist(training$Superplasticizer)
hist(log(training$Superplasticizer))
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
a <- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
df <- training[,a]
b <- prcomp(df[,-1])
summary(b)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain <- createDataPartition(adData$diagnosis, p = 3/4, list=FALSE)
training <- adData[inTrain,]
a <- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
df <- training[,a]
b <- prcomp(df[,-1])
summary(b)
preProc <- preProcess(training[,c(58:69)], method="pca", thresh=0.9)
preProc
testing = adData[-inTrain,]
preProc <- preProcess(training[,c(58:69)], method="pca", thresh=0.8)
preProc
modelFit <- train(training$type -., method="glm",data=trainPC)
g1 <- train(training$diagnosis~., data=a, method="glm")
preProc <- preProcess(subTrain[,c(58:69)], method="pca", thresh=0.8)
subTrain<- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subTrain<- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
df <- training[,a]
b <- prcomp(df[,-1])
preProc <- preProcess(subTrain[,c(58:69)], method="pca", thresh=0.8)
g1 <- train(training$diagnosis~., data=subTrain, method="glm")
df <- training[,subTrain]
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subTrain<- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
df <- training[,subTrain]
b <- prcomp(df[,-1])
preProc <- preProcess(subTrain[,c(58:69)], method="pca", thresh=0.8)
g1 <- train(training$diagnosis~., data=subTrain, method="glm")
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
subTrain<- which(grepl("^IL|diagnosis", colnames(training), ignore.case = F))
df <- training[,subTrain]
b <- prcomp(df[,-1])
preProc <- preProcess(subTrain, method="pca", thresh=0.8)
g1 <- train(training$diagnosis~., data=subTrain, method="glm")
data(mtcars)
head(mtcars)
lm(mpg~as.factor(cyl)+wt,data=mtcars)
lm(mpg~factor(cyl)+wt,data=mtcars)
factor(mtcars$cyl)
data(mtcar)
data(mtcars)
head(mtcars)
lm(mpg~cyl,data=mtcars)
lm(mpg~factor(cyl),data=mtcars)
lm(mpg~factor(cyl)+wt,data=mtcars)
lm(mpg~factor(cyl)+wt-1,data=mtcars)
summary(lm(mpg~factor(cyl)+wt,data=mtcars))
library(rgl)
install.packages(rgl)
install.packages("rgl")
library(rgl)
plot3d(factor(cyl),wt,mpa,data=mtcars)
plot3d(factor(mtcars$cyl),mtcars$wt,mtcars$mpa)
plot3d(factor(mtcars$cyl),mtcars$wt,mtcars$mpg)
mtcars
mtcars(mtcars$cyl=4)
mtcars(mtcars$cyl==4)
mtcars[mtcars$cyl==4]
mtcars$cyl==4
mtcars[mtcars$cyl==4,]
mtcars[mtcars$cyl==8,]
mean(mtcars[mtcars$cyl==8,])
mean(mtcars[mtcars$cyl==8,]$cyl==8)
mean(mtcars[mtcars$cyl==8,]$cyl)
mean(mtcars[mtcars$cyl==8,]$mtg)
mean(mtcars[mtcars$cyl==8,]$mpg)
mean(mtcars[mtcars$cyl==4,]$mpg)
lm(mtg~factor(cyl)+wt,data=mtcars)
lm(mpg~factor(cyl)+wt,data=mtcars)
lm(mpg~factor(cyl)+wt*cyl,data=mtcars)
lm(mpg~factor(cyl)+wt+wt*cyl,data=mtcars)
summary(lm(mpg~factor(cyl)+wt*cyl,data=mtcars))
summary(lm(mpg~factor(cyl)+wt+wt*cyl,data=mtcars))
summary(lm(mpg~factor(cyl)+wt,data=mtcars))
fit1<-lm(mpg~factor(cyl)+wt,data=mtcars)
fit2<-lm(mpg~factor(cyl)+wt+wt*cyl,data=mtcars)
anova(fit1,fit2)
fit2<-lm(mpg~factor(cyl)+wt+wt*factor(cyl),data=mtcars)
anova(fit1,fit2)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
lm(mpg ~ factor(cyl)+ey, data = mtcars)
lm(mpg ~ factor(cyl)+wt, data = mtcars)
?mtcars
head(mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit<-lm(y~x)
hatvalues(fit)
which.max(hatvalues(fit))
dfetas(fit)
dfbetas(fit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal,n=5,m=1-)
head(segmentationOriginal,n=5,m=10)
training <- segmentationOriginal[segmentationOriginal$Case==training,]
training <- segmentationOriginal[segmentationOriginal$Case==Train,]
training <- segmentationOriginal[segmentationOriginal$Case=="Train",]
testing <- segmentationOriginal[segmentationOriginal$Case=="Test",]
?seed
set.seed(125)
modFit <- train(Case~ ., method="rpart",data=training)
library(caret)
modFit <- train(Case~ ., method="rpart",data=training)
modFit <- train(Class~ ., method="rpart",data=training)
print(modFit$finalModel)
library(rattle)
install.packages("ratt;e")
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages(pgmm)
install.packages("pgmm")
data(olive)
install.packages("cepp")
data(olive)
library(cepp)
data(olive)
head(olive)
class(olive$area)
install.packages("C:/Users/Leifu/Desktop/pgmm_1.0.tar.gz", repos = NULL, type = "source")
data(olive)
head(olive)
clas(olive$area)
class(olive$area)
library("pgmm")
data(olive)
head(olive)
factor(olive$Region)
modFit <- train(Area ~., method="rpart",data=olive)
print(modFit$FinalModel)
inTrain <- createDataPartition(y=olive$Area,p=0.7,list=FALSE)
training <- olive[inTrain,]
testing <- olive[-inTrain,]
dim(training)
dim(testing)
modFit <- train(Area ~., method="rpart",data=training)
modFit <- train(Area ~.,data=training)
olive
modFit
head(modfit)
head(modFit)
newdata=as.data.frame(t(colMeans(olive)))
head(newdata)
newdata
factor(olive$Area)
?tree
library(pgmm)
data(olive)
olive=olive[,-1]
newdata=as.data.frame(t(colMeans(olive)))
library(tree)
newdata
install.packages("tree")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
tree1 <- tree(Area ~., data=olive)
library(tree)
tree1 <- tree(Area ~., data=olive)
predict(tree1,newdata)
data(vowel.train)
data(vowel.test)
head(vowel.train)
as.factor(vowel.train$y)
as.factor(vowel.test$y)
class(vowel.test$y)
vowel.test$y <- as.factor(vowel.test$y)
class(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
modFit <- train(y~.,data=vowel.test,method="rf")
?varlmp
library(caret)
?varlmp
??varlmp
varlmp(modFit)
varImp(modFit)
predict(modFit,testing)
predict(modFit,vowel.test)
test <- predict(modFit,vowel.test)
varImp(test)
varImp(vowel.test)
class(modFit)
class(test)
?randomforest
??randomforest
?randomForest
modFit <- randomForest(y ~., data=vowel.train)
varImp(modFit)
sort(varImp(modFit))
?sort
order <- varImp(modFit)
class(order)
head(order)
sort(order$Overall)
setwd("E:/Data Science/Programming Language/R/Coursera/Practical Machine Learning")
install.packages("RANN")
library("RANN")
raw_training <- read.csv("pml-training.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
raw_testing <- read.csv("pml-testing.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
set.seed(1234)
trainingIndex <- createDataPartition(raw_training$classe, list=FALSE, p=.7)
training = raw_training[trainingIndex,]
testing = raw_training[-trainingIndex,]
?nearZeroVar
nzv <- nearZeroVar(training)
training <- training[-nzv]
testing <- testing[-nzv]
raw_testing <- raw_testing[-nzv]
num_features_idx = which(lapply(training,class) %in% c('numeric') )
preModel <- preProcess(training[,num_features_idx], method=c('knnImpute'))
head(preModel)
class(training)
ptraining <- cbind(training$classe, predict(preModel, training[,num_features_idx]))
ptesting <- cbind(testing$classe, predict(preModel, testing[,num_features_idx]))
prtesting <- predict(preModel, raw_testing[,num_features_idx])
names(ptraining)[1] <- 'classe'
names(ptesting)[1] <- 'classe'
View(prtesting)
names(ptraining)
library(randomForest)
rf_model <- randomForest(classe ~ ., ptraining, ntree=500, mtry=32)
training_pred <- predict(rf_model, ptraining)
print(confusionMatrix(training_pred, ptraining$classe))
testing_pred <- predict(rf_model, ptesting)
print(confusionMatrix(testing_pred, ptesting$classe))
answers <- predict(rf_model, prtesting)
answers
source("pml_write_files.R")
pml_write_files(answers)
trainRawData <- read.csv("pml-training.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
testRawData <- read.csv("pml-testing.csv", header=TRUE, sep=",",stringsAsFactors=FALSE)
set.seed(1234)
trainIndex <- createDataPartition(trainRawData$classe, p=0.7，list=FALSE)
training = trainRawData[trainIndex,]
testing = trainRawData[-trainIndex,]
valid_idx = which(lapply(training,class) %in% c('numeric') )
validData<- preProcess(training[,valid_idx], method=c('knnImpute'))
combTrain <- cbind(training$classe, predict(validData, training[,valid_idx]))
combTest <- cbind(testing$classe, predict(validData, testing[,valid_idx]))
predictValid<- predict(validData, testRawData[,valid_idx])
View(combTrain)
View(combTrain)
names(combTrain)[1] <- 'classe'
names(combTest)[1] <- 'classe'
library(randomForest)
modFit <- randomForest(classe ~ ., combTrain, mtry=32)
predictTrain <- predict(modFit, combTrain)
print(confusionMatrix(predictTrain, combTrain$classe))
predictTest <- predict(modFit, combTest)
print(confusionMatrix(predictTest, combTest$classe))
answers <- predict(modFit, predictTest)
answers
answers <- predict(modFit, predictTest)
answers <- predict(modFit, predictValid)
answers
trainRawData <- read.csv("pml-training.csv", header=TRUE, stringsAsFactors=FALSE)
testRawData <- read.csv("pml-testing.csv", header=TRUE, stringsAsFactors=FALSE)
set.seed(1234)
trainIndex <- createDataPartition(trainRawData$classe, p=0.7，list=FALSE)
training = trainRawData[trainIndex,]
testing = trainRawData[-trainIndex,]
trainRawData <- read.csv("pml-training.csv", header=TRUE, stringsAsFactors=FALSE)
testRawData <- read.csv("pml-testing.csv", header=TRUE, stringsAsFactors=FALSE)
set.seed(1234)
trainIndex <- createDataPartition(trainRawData$classe, p=0.7，list=FALSE)
training = trainRawData[trainIndex,]
testing = trainRawData[-trainIndex,]
valid_idx = which(lapply(training,class) %in% c('numeric') )
validData<- preProcess(training[,valid_idx], method=c('knnImpute'))
combTrain <- cbind(training$classe, predict(validData, training[,valid_idx]))
combTest <- cbind(testing$classe, predict(validData, testing[,valid_idx]))
predictValid<- predict(validData, testRawData[,valid_idx])
?preProcess
valid_idx = which(lapply(training,class) %in% c('numeric') )
validData<- preProcess(training[,valid_idx], method="knnImpute")
combTrain <- cbind(training$classe, predict(validData, training[,valid_idx]))
combTest <- cbind(testing$classe, predict(validData, testing[,valid_idx]))
predictValid<- predict(validData, testRawData[,valid_idx])
data(iris)
inTrain <- ceateDataPartition(iris$Species,p=0.7,list=FALSE)
inTrain <- createDataPartition(iris$Species,p=0.7,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~.,data=training, method="rf")
modFit
trainRawData <- read.csv("pml-training.csv", header=TRUE, stringsAsFactors=FALSE)
testRawData <- read.csv("pml-testing.csv", header=TRUE, stringsAsFactors=FALSE)
set.seed(1234)
trainIndex <- createDataPartition(trainRawData$classe, p=0.7，list=FALSE)
training = trainRawData[trainIndex,]
testing = trainRawData[-trainIndex,]
valid_idx = which(lapply(training,class) %in% c('numeric') )
validData<- preProcess(training[,valid_idx], method="knnImpute")
combTrain <- cbind(training$classe, predict(validData, training[,valid_idx]))
combTest <- cbind(testing$classe, predict(validData, testing[,valid_idx]))
predictValid<- predict(validData, testRawData[,valid_idx])
names(combTrain)[1] <- 'classe'
names(combTest)[1] <- 'classe'
modFit <- randomForest(classe ~ ., combTrain)
modFit
predictTrain <- predict(modFit, combTrain)
print(confusionMatrix(predictTrain, combTrain$classe))
predictTest <- predict(modFit, combTest)
print(confusionMatrix(predictTest, combTest$classe))
answers <- predict(modFit, predictValid)
answers
